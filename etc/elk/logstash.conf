input {
  # RabbitMQ Input
  rabbitmq {
    host => "host.docker.internal" # Use the name of your RabbitMQ service defined in Docker Compose
    port => 5672
    queue => "queue.sia.data.watcher" # Specify your RabbitMQ queue name here
    user => "${RABBITMQ_USER}" # Use the RabbitMQ user
    password => "${RABBITMQ_PASSWORD}" # Use the RabbitMQ password
    durable => true # Set to true if your queue is durable
    codec => "json" # Adjust based on the expected message format
  }

  # File Input
  file {
    mode => "read"
    path => "/usr/share/logstash/ingest_data/*.csv" # Specifying only CSV files
    exit_after_read => true # This tells Logstash to exit after reading the file
    file_completed_action => "log" # This tells Logstash to log to the specified file once done reading
    file_completed_log_path => "/usr/share/logstash/ingest_data/logstash_completed.log"
  }
}

filter {
  # Add your filters here if necessary
}

output {
  elasticsearch {
    index => "logstash-%{+YYYY.MM.dd}"
    hosts => "${ELASTIC_HOSTS}"
    user => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}"
    cacert => "certs/ca/ca.crt"
  }
}
